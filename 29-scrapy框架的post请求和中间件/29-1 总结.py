"""
1.爬虫器内定义起始url(start_url),构造一个request请求对象
 由于是起始url,request请求对象的构造是自动的
 把request请求对象交给了引擎

2.引擎拿到了request，交给了调度器
    --自动完成，不需要我们关心，在底层实现

3.自动
调度器把request请求入队列，出队列，交给引擎

4.自动
引擎把request请求对象交给下载器

5.自动
下载器拿到了request请求对象发送网络请求，得到响应response
交给了引擎

6.引擎把响应response给了爬虫器
根据response去进行解析
    --(1) 如果是需要保存的数据，那么就构造成item对象，交给引擎
    --(2) 如果是需要继续发送请求的url,手动构建request请求对象，交给引擎

7.引擎拿到了爬虫器yield过来的数据
    --(1) 如果是item对象，引擎就交给管道pipeline进行保存
    --(2) 如果是request请求对象，引擎就交给调度器
"""